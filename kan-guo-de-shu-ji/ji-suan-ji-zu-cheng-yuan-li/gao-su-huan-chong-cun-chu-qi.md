### 概述

#### 问题提出

* 避免CPU"空等"现象
* CPU和主存\(DRAM\)的速度差异

![](/assets/js-13.2.4.4-1.png)

* 程序访问的局部性原理

#### cache的工作原理

* 主存和缓存的编址
  * 主存和缓存按块存储，块的大小相同
* 命中与未命中
* cache的命中率
  * CPU欲访问的信息在cache中的比率
  * 命中率与cache的容量与块长有关

### cache-主存系统的效率

* 效率e与命中率有关

* e = 访问Cache的时间 / 平均访问时间 x 100%

```
设Cache命中率为h，访问Cache的时间为Tc，访问主存的时间为Tm

e = Tc / (hxTc+(1-h)xTm) x 100%

例题:假设CPU执行某段程序时，其命中率为0.97，cache的存取周期为50ns，主存的存取周期为200ns，
则cache-主存系统的平均访问时间为__。

平均访问时间 = 50x0.95 + 0.03x200 = 48.5 + 6 = 54.5 ns
```

### Cache的基本结构

* cache地址
  * 块号-块内地址

```
将主存地址映射到缓存中定位称为地址映射，将主存地址变换成缓存地址称为地址变换，
当新的主存块需要调入缓存中，而它的可用位置又被占用时，需根据替换算法解决调入问题。
```

```
Cache 存储体
主存Cache地址映射变换机构
Cache替换机构
```

### Cache的读写操作

读

![](/assets/13.2.4.4-1.png)

写

* 会造成cache和主存的不一致
* 写直达法
  * 写操作时数据即写入cache又写入主存
  * 写操作时间就是访问主存的时间，cache块退出时，不需要对主存执行写操作，更新策略比较容易实现
* 写回法
  * 写操作时只把数据写入cache而不写入主存，当Cache数据被替换出去时才写回主存
  * 写操作时间就是访问cache的时间

```
写直达法能随时保证主存和cache的数据始终一致，但增加了访存次数
```

### Cache的改进

* 增加Cache的级数
  * 片载\(片内\)Cache
  * 片外Cache
* 统一缓存和分立缓存
  * 指令Cache、数据Cache
  * 与指令执行的控制方式有关

### 高速缓冲存储器

#### 主存的地址映射

* 直接映射
  * 主存地址
    * 主存字块标记
    * Cache字块地址
    * 字块内地址

* 全相联映射
  * 主存地址
    * 主存字块标记
    * 字块内地址

```
缓存的地址映射中，若主存中的任一块均可映射到缓存内的任一块的位置上，称作全相联映射
```

* 组相联映射
  * 主存地址
    * 主存字块标记
    * 组地址
    * 字块内地址
  * 某一主存块j按模Q映射到缓存的第i组中的任一块

```
缓存的地址映射中，全相联映射 比较多的采用“按内容寻址”的相联存储器来实现
```

### 替换算法

1. 先进先出\(FIFO\)算法
2. 近期最少使用\(LRU\)算法

* 直接:某一主存块 只能固定映射到某一缓存块
* 全相联:某一主存块 能 映射到 任一 缓存块
* 组相联:某一主存块 只能 映射到某一缓存 组中的 缓存块








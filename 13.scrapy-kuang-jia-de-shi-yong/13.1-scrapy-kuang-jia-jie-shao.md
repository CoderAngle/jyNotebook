### 1.架构

![](/assets/spider-14.14.1-1.png)

scrapy架构可分为如下部分:

* Engine 引擎，处理整个系统的数据流处理、触发事务，是整个框架的核心
* Item 项目，它定义了爬取结果的数据结构，爬取的数据会被赋值成该 Item 对象
* Scheduler 调度器，接受引擎发过来的请求并将其 列中 在引擎再次请求的时候将请求提供给引擎
* Down loader 下载器，下载网页内容，并将网页 容返回给蜘蛛
* Spiders 蜘蛛，其内定义了爬取的逻辑和网页 解析规 ，它主要负责解析响应并生成提取结果和新的请求
* Item Pipel ne 项目管道，负责处理由蜘蛛从网页中 取的项目，它的主要任务是清洗、验证和存储数据
* Downloader Middlewares 下载器中间件，位于引擎和下载器之 的钩子框架，主要处理引擎与下载器之间的请求及响应
* Spide Middlewares 蜘蛛中间件，位于引擎和蜘蛛之 的钩子框架，主要处理蜘蛛输入的响应和输出的结果及新的请求

### 2.数据流

Scrapy 中的数据流由引擎控制，数据流的过程如下

* \(1\) Engin 首先打开一个网站，找到处理该网站的 Spider ，并向该 Spider 请求第一个要爬取的 URL
* \(2\) in er 中获取到第一个要爬取的 URL ，并通过 dul ques 的形式调度
* \(3\) gi Sc dul 请求下一个要爬取的 URL
* \(4\) Sc duler 返回下一个要爬取的 URL in , ngin URL 通过 Downlo der MiddJewares发给 Down oa er 下载

* \(5 ）一旦页面下载完毕， ow oa 生成该页面的 Re pon ，并将其通过 wnload Middlewares发送给 in

* \(6\) in 从下载器中接收到 espon se ，并将其通过 Spider Middleware 发送给 Spid 处理
* \(7\) pid er 处理 es ponse ，并返回爬取到的 It 及新的 Reque ngin
* \(8\) ine pid er 返回的 It It Pip line ，将新 Requ st Schedul
* \(9）重复第（ ）步到第（ ）步，直到 Sc dule 中没有更多的 que ngine 关闭该网站，爬取结束



